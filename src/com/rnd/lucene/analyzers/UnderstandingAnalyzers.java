package com.rnd.lucene.analyzers;

import java.io.IOException;

import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.Tokenizer;
import org.apache.lucene.analysis.core.KeywordAnalyzer;
import org.apache.lucene.analysis.core.KeywordTokenizer;
import org.apache.lucene.analysis.core.SimpleAnalyzer;
import org.apache.lucene.analysis.core.StopAnalyzer;
import org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter;
import org.apache.lucene.analysis.shingle.ShingleAnalyzerWrapper;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.analysis.standard.StandardFilter;
import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;

public class UnderstandingAnalyzers 
{
	public static void main(String arg[]) throws Exception
	{
		String lstrText = null;
		
		if(arg.length != 0)
		{
			lstrText = arg[0];
		}
		else
		{
			/*
			BufferedReader lReader = new BufferedReader(new InputStreamReader(System.in));

			System.out.println("\nEnter text to be analyzed : ");
			
			System.out.println("Hint : Enter text with multiple mixed case words.");
			
			lstrText = lReader.readLine();
			
			lReader.close();
			*/
			
			lstrText = "The quick fox name Lucene ran away far too soon.";
		}
		
		System.out.println("\nTEXT : "+lstrText+"\n");
		System.out.println("Analyzing Tokens generated by different Analyzers : \n");
		
		System.out.println("1. Standard Analyzer");
		displayTokens(new StandardAnalyzer(), lstrText);
		
		System.out.println("2. Keyword Analyzer");
		displayTokens(new KeywordAnalyzer(), lstrText);
		
		System.out.println("3. Simple Analyzer");
		displayTokens(new SimpleAnalyzer(), lstrText);
		
		System.out.println("4. Shingle Analyzer");
		displayTokens(new ShingleAnalyzerWrapper(), lstrText);
		
		System.out.println("5. Stop Analyzer");
		displayTokens(new StopAnalyzer(), lstrText);
		
		System.out.println("6. Custom Analyzer with Edge N Gram Filter");
		Analyzer lAnalyzer = new Analyzer() {
			
			@Override
			protected TokenStreamComponents createComponents(String fieldName) 
			{
				Tokenizer lSource = new KeywordTokenizer();
				
				TokenStream lResult = new StandardFilter(lSource);
				lResult = new EdgeNGramTokenFilter(lResult, 3, 100);
				
				return new TokenStreamComponents(lSource, lResult);
			}
		};
		displayTokens(lAnalyzer, lstrText);
		
	}
	
	public static void displayTokens(Analyzer pAnalyzer, String pText) throws IOException
	{
		TokenStream lTokenStream = pAnalyzer.tokenStream("", pText);
		
		CharTermAttribute lAttribute = lTokenStream.addAttribute(CharTermAttribute.class);
		
		lTokenStream.reset();
		
		while(lTokenStream.incrementToken())
		{
			System.out.println("\t"+lAttribute.toString());
		}
		System.out.println();
	}
}
